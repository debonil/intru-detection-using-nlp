{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rm09UPcjR9-g"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Read the training CSV file containing normal traffic data\n",
        "df_normal_train = pd.read_csv('train_normal.csv')\n",
        "\n",
        "# Read the testing CSV file containing abnormal traffic data\n",
        "df_test_abnormal = pd.read_csv('test_abnormal.csv')\n",
        "\n",
        "# Read the testing CSV file containing normal traffic data\n",
        "df_test_normal = pd.read_csv('test_normal.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jvebdEKSBj6",
        "outputId": "d1cd0ab1-7bb6-4109-c1cf-7e14fb8d6b6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Ravi_Kumar2\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "\n",
        "df_concat = pd.concat([df_normal_train, df_test_abnormal, df_test_normal])\n",
        "\n",
        "# Shuffle the concatenated dataframe\n",
        "df_shuffled = df_concat.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lra1x9RSEBt",
        "outputId": "f0a5cd96-0386-46fe-b440-15f11034fd0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Ravi_Kumar2\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "preprocessed = []\n",
        "for request in df_shuffled['request']:\n",
        "    request = request.lower()\n",
        "    #request = ''.join(e for e in request if e.isalnum() or e.isspace())\n",
        "    words = nltk.word_tokenize(request)\n",
        "    #words = [w for w in words if w not in stop_words]\n",
        "    preprocessed.append(' '.join(words))\n",
        "\n",
        "for request in df_test_abnormal['request']:\n",
        "    request = request.lower()\n",
        "    #request = ''.join(e for e in request if e.isalnum() or e.isspace())\n",
        "    words = nltk.word_tokenize(request)\n",
        "    #words = [w for w in words if w not in stop_words]\n",
        "    preprocessed.append(' '.join(words))\n",
        "\n",
        "for request in df_test_normal['request']:\n",
        "    request = request.lower()\n",
        "    #request = ''.join(e for e in request if e.isalnum() or e.isspace())\n",
        "    words = nltk.word_tokenize(request)\n",
        "    #words = [w for w in words if w not in stop_words]\n",
        "    preprocessed.append(' '.join(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sqaVinDzSGyn"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(preprocessed)\n",
        "dictionary = vectorizer.vocabulary_\n",
        "\n",
        "# Convert HTTP requests to feature vectors\n",
        "x_train_normal = vectorizer.transform(df_shuffled['request']).toarray()\n",
        "y_train_normal = df_shuffled['label']\n",
        "\n",
        "x_test_abnormal = vectorizer.transform(df_test_abnormal['request']).toarray()\n",
        "y_test_abnormal = df_test_abnormal['label'].dropna()\n",
        "\n",
        "x_test_normal = vectorizer.transform(df_test_normal['request']).toarray()\n",
        "y_test_normal = df_test_normal['label'].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y0OfRh3OSI0N"
      },
      "outputs": [],
      "source": [
        "# Split the shuffled dataset into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train_normal, y_train_normal, test_size=0.2, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "    # Define the models to be trained and tested\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Support Vector Machine\": SVC(),\n",
        "    \"Multilayer Perceptron\": MLPClassifier()\n",
        "}\n",
        "\n",
        "ensemble_models = {\n",
        "    \"Bagging\": BaggingClassifier(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Stacking\": StackingClassifier(estimators=list(models.items()))\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "models = { \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "          \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "          \"Support Vector Machine\": SVC(random_state=42),\n",
        "          \"Multilayer Perceptron\": MLPClassifier(),\n",
        "          \"Bagging\": BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=42), random_state=42),\n",
        "          \"AdaBoost\":AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=42), random_state=42),\n",
        "          \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "          \"Stacking\": StackingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=42)),\n",
        "                                         ('rf', RandomForestClassifier(random_state=42)),\n",
        "                                         ('svm', SVC(random_state=42)),\n",
        "                                         ('mlp', MLPClassifier(random_state=42))],\n",
        "                             final_estimator=DecisionTreeClassifier(random_state=42),\n",
        "                             passthrough=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0Z6exM4dSMIc"
      },
      "outputs": [],
      "source": [
        "# Train and test the models\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred_abnormal = model.predict(x_test_abnormal)\n",
        "    accuracy = accuracy_score(y_test_abnormal, y_pred_abnormal)\n",
        "    f1 = f1_score(y_test_normal, y_pred_normal)\n",
        "    print(f\"{name} accuracy on abnormal traffic data: {accuracy}\")\n",
        "    print(f\"{name} F1 on normal traffic data: {f1}\")\n",
        "    \n",
        "    y_pred_normal = model.predict(x_test_normal)\n",
        "    accuracy = accuracy_score(y_test_normal, y_pred_normal)\n",
        "    f1 = f1_score(y_test_normal, y_pred_normal)\n",
        "    print(f\"{name} accuracy on normal traffic data: {accuracy}\")\n",
        "    print(f\"{name} F1 on normal traffic data: {f1}\")\n",
        "    \n",
        "    report = classification_report(y_test_abnormal, y_pred_abnormal)\n",
        "    print(f\"{name} classification report on abnormal traffic data:\\n{report}\")\n",
        "    \n",
        "    report = classification_report(y_test_normal, y_pred_normal)\n",
        "    print(f\"{name} classification report on normal traffic data:\\n{report}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "conda_env",
      "language": "python",
      "name": "conda_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
